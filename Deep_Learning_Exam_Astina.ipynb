{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b78b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.evaluate import bias_variance_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25beb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true=pd.read_csv('True.csv')\n",
    "df_fake=pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ee2acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65dba7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['politicsNews', 'worldnews'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true['subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111c19c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c80710f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'subject', 'date'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847a14b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'subject', 'date'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b8f7c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21417, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ad9e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23481, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499199ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      object\n",
       "text       object\n",
       "subject    object\n",
       "date       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160bdc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      object\n",
       "text       object\n",
       "subject    object\n",
       "date       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d372920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                    title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "21412  'Fully committed' NATO backs new U.S. approach...   \n",
       "21413  LexisNexis withdrew two products from Chinese ...   \n",
       "21414  Minsk cultural hub becomes haven from authorities   \n",
       "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
       "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...     worldnews   \n",
       "21413  LONDON (Reuters) - LexisNexis, a provider of l...     worldnews   \n",
       "21414  MINSK (Reuters) - In the shadow of disused Sov...     worldnews   \n",
       "21415  MOSCOW (Reuters) - Vatican Secretary of State ...     worldnews   \n",
       "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...     worldnews   \n",
       "\n",
       "                     date  \n",
       "0      December 31, 2017   \n",
       "1      December 29, 2017   \n",
       "2      December 31, 2017   \n",
       "3      December 30, 2017   \n",
       "4      December 29, 2017   \n",
       "...                   ...  \n",
       "21412    August 22, 2017   \n",
       "21413    August 22, 2017   \n",
       "21414    August 22, 2017   \n",
       "21415    August 22, 2017   \n",
       "21416    August 22, 2017   \n",
       "\n",
       "[21417 rows x 4 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72abebf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                    title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "23476  McPain: John McCain Furious That Iran Treated ...   \n",
       "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "23479  How to Blow $700 Million: Al Jazeera America F...   \n",
       "23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text      subject  \\\n",
       "0      Donald Trump just couldn t wish all Americans ...         News   \n",
       "1      House Intelligence Committee Chairman Devin Nu...         News   \n",
       "2      On Friday, it was revealed that former Milwauk...         News   \n",
       "3      On Christmas day, Donald Trump announced that ...         News   \n",
       "4      Pope Francis used his annual Christmas Day mes...         News   \n",
       "...                                                  ...          ...   \n",
       "23476  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n",
       "23477  21st Century Wire says It s a familiar theme. ...  Middle-east   \n",
       "23478  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n",
       "23479  21st Century Wire says Al Jazeera America will...  Middle-east   \n",
       "23480  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n",
       "\n",
       "                    date  \n",
       "0      December 31, 2017  \n",
       "1      December 31, 2017  \n",
       "2      December 30, 2017  \n",
       "3      December 29, 2017  \n",
       "4      December 25, 2017  \n",
       "...                  ...  \n",
       "23476   January 16, 2016  \n",
       "23477   January 16, 2016  \n",
       "23478   January 15, 2016  \n",
       "23479   January 14, 2016  \n",
       "23480   January 12, 2016  \n",
       "\n",
       "[23481 rows x 4 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430a1c3",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "841ee07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21417 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title   text  subject   date\n",
       "0      False  False    False  False\n",
       "1      False  False    False  False\n",
       "2      False  False    False  False\n",
       "3      False  False    False  False\n",
       "4      False  False    False  False\n",
       "...      ...    ...      ...    ...\n",
       "21412  False  False    False  False\n",
       "21413  False  False    False  False\n",
       "21414  False  False    False  False\n",
       "21415  False  False    False  False\n",
       "21416  False  False    False  False\n",
       "\n",
       "[21417 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefd31df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      0\n",
       "text       0\n",
       "subject    0\n",
       "date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f4ffdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title   text  subject   date\n",
       "0      False  False    False  False\n",
       "1      False  False    False  False\n",
       "2      False  False    False  False\n",
       "3      False  False    False  False\n",
       "4      False  False    False  False\n",
       "...      ...    ...      ...    ...\n",
       "23476  False  False    False  False\n",
       "23477  False  False    False  False\n",
       "23478  False  False    False  False\n",
       "23479  False  False    False  False\n",
       "23480  False  False    False  False\n",
       "\n",
       "[23481 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27680b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      0\n",
       "text       0\n",
       "subject    0\n",
       "date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af668de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21417"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75f67ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23481"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7407f984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'subject', 'date'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee7ac9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'subject', 'date'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adafddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "true=df_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a370738",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake=df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2cbf927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23481, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aae1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews = []\n",
    "for i in range(23481):\n",
    "  fakenews.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdcc285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.insert(4, \"class\", fakenews, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9166ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatening fake and real news together in one dataset\n",
    "total = pd.concat([true,fake])\n",
    "total = total.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4848c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>BOYCOTT! GOLDMAN SACHS Uses Union Thug Tactics...</td>\n",
       "      <td>This is how the unions do things in America. I...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Sep 7, 2016</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>Trump says China tried but failed to help on N...</td>\n",
       "      <td>WASHINGTON/BEIJING (Reuters) - Chinese efforts...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 20, 2017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>Venezuela making interest payments on foreign ...</td>\n",
       "      <td>CARACAS (Reuters) - Venezuela has started maki...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 14, 2017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>CRYBABY NANCY PELOSI Taunts Trump On Healthcar...</td>\n",
       "      <td>https://www.youtube.com/watch?v=SH0pRtK9sAE</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Mar 24, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22007</th>\n",
       "      <td>Boiler Room EP #126 – Immigration Consternation</td>\n",
       "      <td>Tune in to the Alternate Current Radio Network...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>September 15, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "20010  BOYCOTT! GOLDMAN SACHS Uses Union Thug Tactics...   \n",
       "3100   Trump says China tried but failed to help on N...   \n",
       "14825  Venezuela making interest payments on foreign ...   \n",
       "16186  CRYBABY NANCY PELOSI Taunts Trump On Healthcar...   \n",
       "22007    Boiler Room EP #126 – Immigration Consternation   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "20010  This is how the unions do things in America. I...        left-news   \n",
       "3100   WASHINGTON/BEIJING (Reuters) - Chinese efforts...     politicsNews   \n",
       "14825  CARACAS (Reuters) - Venezuela has started maki...        worldnews   \n",
       "16186        https://www.youtube.com/watch?v=SH0pRtK9sAE  Government News   \n",
       "22007  Tune in to the Alternate Current Radio Network...          US_News   \n",
       "\n",
       "                     date  class  \n",
       "20010         Sep 7, 2016    1.0  \n",
       "3100       June 20, 2017     NaN  \n",
       "14825  November 14, 2017     NaN  \n",
       "16186        Mar 24, 2017    1.0  \n",
       "22007  September 15, 2017    1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5d0fba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a652dc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'subject', 'date', 'class'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a249b972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>BOYCOTT! GOLDMAN SACHS Uses Union Thug Tactics...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>Trump says China tried but failed to help on N...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>Venezuela making interest payments on foreign ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>CRYBABY NANCY PELOSI Taunts Trump On Healthcar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22007</th>\n",
       "      <td>Boiler Room EP #126 – Immigration Consternation</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  class\n",
       "20010  BOYCOTT! GOLDMAN SACHS Uses Union Thug Tactics...    1.0\n",
       "3100   Trump says China tried but failed to help on N...    NaN\n",
       "14825  Venezuela making interest payments on foreign ...    NaN\n",
       "16186  CRYBABY NANCY PELOSI Taunts Trump On Healthcar...    1.0\n",
       "22007    Boiler Room EP #126 – Immigration Consternation    1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We require only title and class \n",
    "data = total[['title','class']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b973854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting title on a histogram\n",
    "import seaborn as sns\n",
    "\n",
    "x = data['title'].apply(len).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf8971",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76f56369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6496\\3633389291.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['title'] = data['title'].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>boycott! goldman sachs uses union thug tactics...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>trump says china tried but failed to help on n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>venezuela making interest payments on foreign ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>crybaby nancy pelosi taunts trump on healthcar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22007</th>\n",
       "      <td>boiler room ep #126 – immigration consternation</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  class\n",
       "20010  boycott! goldman sachs uses union thug tactics...    1.0\n",
       "3100   trump says china tried but failed to help on n...    NaN\n",
       "14825  venezuela making interest payments on foreign ...    NaN\n",
       "16186  crybaby nancy pelosi taunts trump on healthcar...    1.0\n",
       "22007    boiler room ep #126 – immigration consternation    1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "#Lowercase letters\n",
    "data['title'] = data['title'].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84cb5528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', \"'\", '\"']\n"
     ]
    }
   ],
   "source": [
    "#Punctuation\n",
    "punc = list(string.punctuation)\n",
    "#Adding \\\n",
    "punc.append('\\'')\n",
    "#Adding \"\"\n",
    "punc.append('\"')\n",
    "print(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea59c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all punctuations\n",
    "def removePunc(text):\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84f35e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6496\\1517026403.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['title'] = data['title'].apply(removePunc)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>boycott goldman sachs uses union thug tactics ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>trump says china tried but failed to help on n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>venezuela making interest payments on foreign ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>crybaby nancy pelosi taunts trump on healthcar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22007</th>\n",
       "      <td>boiler room ep 126 – immigration consternation</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  class\n",
       "20010  boycott goldman sachs uses union thug tactics ...    1.0\n",
       "3100   trump says china tried but failed to help on n...    NaN\n",
       "14825  venezuela making interest payments on foreign ...    NaN\n",
       "16186  crybaby nancy pelosi taunts trump on healthcar...    1.0\n",
       "22007     boiler room ep 126 – immigration consternation    1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title'] = data['title'].apply(removePunc)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b248ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc79baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "190c39e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d45d6b",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "691caa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6496\\2676297259.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['title'] = data.apply(lambda row: nltk.word_tokenize(row['title']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "data['title'] = data.apply(lambda row: nltk.word_tokenize(row['title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce6f2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define text lemmatization model \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87c87dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(data):\n",
    "  return [lemmatizer.lemmatize(w) for w in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad21e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6496\\1424781970.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['title'] = data['title'].apply(lemma)\n"
     ]
    }
   ],
   "source": [
    "data['title'] = data['title'].apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d90321d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define all stopwords in the English language (it, was, for, etc.)\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af3998f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6496\\128912987.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['title'] = data['title'].apply(lambda x: [i for i in x if i not in stop])\n"
     ]
    }
   ],
   "source": [
    "#Remove stopwords \n",
    "data['title'] = data['title'].apply(lambda x: [i for i in x if i not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "228ec335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>[boycott, goldman, sachs, us, union, thug, tac...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>[trump, say, china, tried, failed, help, north...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>[venezuela, making, interest, payment, foreign...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>[crybaby, nancy, pelosi, taunt, trump, healthc...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22007</th>\n",
       "      <td>[boiler, room, ep, 126, –, immigration, conste...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  class\n",
       "20010  [boycott, goldman, sachs, us, union, thug, tac...    1.0\n",
       "3100   [trump, say, china, tried, failed, help, north...    NaN\n",
       "14825  [venezuela, making, interest, payment, foreign...    NaN\n",
       "16186  [crybaby, nancy, pelosi, taunt, trump, healthc...    1.0\n",
       "22007  [boiler, room, ep, 126, –, immigration, conste...    1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8ae6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "743aff81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20010    1.0\n",
       "3100     NaN\n",
       "14825    NaN\n",
       "16186    1.0\n",
       "22007    1.0\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['class']\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cafd3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing dataset\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=1000)\n",
    "title_train, title_test, y_train, y_test = train_test_split(data['title'],labels, test_size=0.2,random_state=1000)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data['total'], data.label, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82892495",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "531d6d18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      3\u001b[0m count_vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m----> 4\u001b[0m count_train \u001b[38;5;241m=\u001b[39m count_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[0;32m      5\u001b[0m count_test \u001b[38;5;241m=\u001b[39m count_vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Count Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english') \n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d622cf24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      2\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m tfidf_train \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[0;32m      4\u001b[0m tfidf_test \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2664e32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[1;32m----> 3\u001b[0m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train)\n\u001b[0;32m      4\u001b[0m X_train\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[0;32m      5\u001b[0m X_test\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer.fit(X_train)\n",
    "X_train=vectorizer.transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9027a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "937c5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f44ac1e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reg\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c288a9ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Logistic Regression \u001b[39;00m\n\u001b[0;32m      2\u001b[0m reg \u001b[38;5;241m=\u001b[39m LogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m reg\u001b[38;5;241m.\u001b[39mfit(\u001b[43mcount_train\u001b[49m, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "reg = LogisticRegression(C=1e5)\n",
    "reg.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40752523",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_reg_count \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mcount_test\u001b[49m)\n\u001b[0;32m      2\u001b[0m acc_reg_count \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test,pred_logreg_count)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_test' is not defined"
     ]
    }
   ],
   "source": [
    "pred_reg_count = reg.predict(count_test)\n",
    "acc_reg_count = metrics.accuracy_score(y_test,pred_logreg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a69b0c38",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_reg_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43macc_reg_count\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'acc_reg_count' is not defined"
     ]
    }
   ],
   "source": [
    "print(acc_reg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f57a682c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_reg_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cm3 \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(y_test, \u001b[43mpred_reg_count\u001b[49m, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      3\u001b[0m plot_confusion_matrix(cm3, classes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRUE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAKE\u001b[39m\u001b[38;5;124m'\u001b[39m], title \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion matrix for a Logistic Regression with Count Vectorizer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_reg_count' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "cm3 = metrics.confusion_matrix(y_test, pred_reg_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm3, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97551262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20010    1.0\n",
       "3100     NaN\n",
       "14825    NaN\n",
       "16186    1.0\n",
       "22007    1.0\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=data['class']\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7bd4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df53cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973531bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87408b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30155f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9449fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd980628",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a3cd4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert each series of words to a word to vector embedding\n",
    "indiv = []\n",
    "for i in title_train:\n",
    "  temp = np.array(embed(i))\n",
    " \n",
    "  indiv.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c99e5e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35918, 34, 250)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accounts for different length of words\n",
    "indiv = tf.keras.preprocessing.sequence.pad_sequences(indiv,dtype='float')\n",
    "indiv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c9930440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert each of the testing data series to a word to vector embedding\n",
    "test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06af0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in title_test:\n",
    "  temp = np.array(embed(i))\n",
    "  test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f093fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accounts for the different length of words in test data\n",
    "test = tf.keras.preprocessing.sequence.pad_sequences(test,dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "559e93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential model\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9142fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.LSTM(50))\n",
    "model.add(tf.keras.layers.Dense(20,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb78228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-4),\\\n",
    "              loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e192e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1123/1123 [==============================] - 32s 21ms/step - loss: nan - accuracy: 2.7841e-04 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1123/1123 [==============================] - 20s 18ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1123/1123 [==============================] - 20s 18ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1123/1123 [==============================] - 20s 18ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1123/1123 [==============================] - 20s 18ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1123/1123 [==============================] - 20s 18ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1123/1123 [==============================] - 21s 18ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1123/1123 [==============================] - 24s 22ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1123/1123 [==============================] - 22s 20ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1123/1123 [==============================] - 21s 19ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d269a3ce80>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(indiv, y_train,validation_data=[test,y_test],epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3df8ee53",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#TfidfVectorizer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tfidf_vectorizer\u001b[38;5;241m=\u001b[39mTfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m tfidf_train\u001b[38;5;241m=\u001b[39m\u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle_train\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m tfidf_test\u001b[38;5;241m=\u001b[39mtfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(title_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2078\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2072\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2073\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2074\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2075\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2076\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2077\u001b[0m )\n\u001b[1;32m-> 2078\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2081\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1338\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1330\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1332\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1333\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1334\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1335\u001b[0m             )\n\u001b[0;32m   1336\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1338\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1341\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1209\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1208\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1210\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[1;32m---> 69\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "#TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(title_train) \n",
    "tfidf_test=tfidf_vectorizer.transform(title_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f0597930",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_classification\n\u001b[0;32m      3\u001b[0m pac\u001b[38;5;241m=\u001b[39mPassiveAggressiveClassifier(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m pac\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtfidf_train\u001b[49m,y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4da0a98a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mpac\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtfidf_test\u001b[49m)\n\u001b[0;32m      2\u001b[0m score\u001b[38;5;241m=\u001b[39maccuracy_score(y_test,y_pred)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(score\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred=pac.predict(tfidf_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad23a371",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Confusion Matrix\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 3\u001b[0m confusion_matrix(y_test,\u001b[43my_pred\u001b[49m, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAKE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREAL\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "251a6a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.11,>=2.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.19.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.21.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (4.1.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (14.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (61.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.42.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.27.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.0.7)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.33.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.27.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.0.4)\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-text\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "#bert preprocesser and bert encoder from tensorflow_hub\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3df7e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c02a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(), dtype=tf.string, name='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75d3f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT layers\n",
    "processed = bert_preprocess(input_layer)\n",
    "output = bert_encoder(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd0fca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer = tf.keras.layers.Dropout(0.2, name='dropout')(output['pooled_output'])\n",
    "layer = tf.keras.layers.Dense(10,activation='relu', name='hidden')(layer)\n",
    "layer = tf.keras.layers.Dense(1,activation='sigmoid', name='output')(layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_layer],outputs=[layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3d1f65f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(title_test,y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(title_train,y_train,epochs=5)\n",
    "model.evaluate(title_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca47429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e895d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a864b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec0d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec79e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
